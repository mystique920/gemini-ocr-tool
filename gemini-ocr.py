#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Google Gemini Models for Object Detection, Image Captioning, and OCR
Adapted from Colab notebook: https://colab.research.google.com/drive/1BDBUaLAtI0AKnPafSlhyvmm0q0PN3UYo
"""

import argparse
import json
import os
from pathlib import Path

import cv2
import google.generativeai as genai
from PIL import Image
from ultralytics.utils.downloads import safe_download
from ultralytics.utils.plotting import Annotator, colors

# Import dotenv for loading environment variables from .env file
from dotenv import load_dotenv

# Load environment variables from .env file if it exists
load_dotenv()

# Default API key - override this in .env file or with environment variable
GEMINI_API_KEY = None


def setup_gemini_client(api_key=None):
    """
    Set up the Gemini client with your API key.
    
    Args:
        api_key (str, optional): Your Google Gemini API key. If None, will try to read from environment variables.
    
    Returns:
        genai.GenerativeModel: Initialized Gemini model
    """
    # Priority order:
    # 1. Explicitly provided api_key
    # 2. GEMINI_API_KEY from .env file or environment
    # 3. GOOGLE_API_KEY from environment
    if api_key is None:
        api_key = os.environ.get("GEMINI_API_KEY") or GEMINI_API_KEY
        
    if api_key is None:
        api_key = os.environ.get("GOOGLE_API_KEY")
        
    if not api_key:
        raise ValueError(
            "API key not provided. Please provide it in one of these ways:\n"
            "1. Create a .env file with GEMINI_API_KEY='your-key'\n"
            "2. Set GEMINI_API_KEY in the script\n"
            "3. Set GEMINI_API_KEY environment variable\n"
            "4. Set GOOGLE_API_KEY environment variable\n"
            "5. Use the --api-key command line argument"
        )
    
    # Configure the Gemini API
    genai.configure(api_key=api_key)
    
    # Create and return the model
    return genai.GenerativeModel('gemini-2.5-pro-exp-03-25')


def inference(model, image, prompt, temp=0.5):
    """
    Performs inference using Google Gemini Pro Vision model.

    Args:
        model (genai.GenerativeModel): Initialized Gemini model
        image (PIL.Image): The image input
        prompt (str): A text prompt to guide the model's response.
        temp (float, optional): Sampling temperature for response randomness. Default is 0.5.

    Returns:
        str: The text response generated by the Gemini model based on the prompt and image.
    """
    response = model.generate_content(
        [prompt, image],
        generation_config=genai.types.GenerationConfig(
            temperature=temp,  # Controls creativity vs. determinism in output
        ),
    )

    return response.text  # Return the generated textual response


def read_image(filename=None, image_dir=None):
    """
    Read an image from a file or download it if it doesn't exist.
    
    Args:
        filename (str, optional): Name of the image file. Default is "bus.jpg".
        image_dir (str, optional): Directory to save the downloaded image. Default is current directory.
    
    Returns:
        tuple: (PIL.Image, width, height)
    """
    if filename is None:
        filename = "bus.jpg"  # or "zidane.jpg"
    
    if image_dir is None:
        image_dir = "."
    
    image_path = Path(image_dir) / filename
    
    # Download the image if it doesn't exist
    if not image_path.exists():
        safe_download(f"https://github.com/ultralytics/assets/releases/download/v0.0.0/{filename}", 
                      dir=str(image_dir))

    # Read image with opencv
    image_cv = cv2.cvtColor(cv2.imread(str(image_path)), cv2.COLOR_BGR2RGB)

    # Extract width and height
    h, w = image_cv.shape[:2]

    # Convert to PIL Image
    return Image.fromarray(image_cv), w, h


def clean_results(results):
    """
    Clean the results for visualization by removing Markdown formatting.
    
    Args:
        results (str): Raw string output from the model
        
    Returns:
        str: Cleaned string ready for JSON parsing
    """
    return results.strip().removeprefix("```json").removesuffix("```").strip()


def save_annotated_image(image, filename, output_dir="output"):
    """
    Save the annotated image to disk.
    
    Args:
        image (PIL.Image): Annotated image
        filename (str): Output filename
        output_dir (str): Output directory
    """
    os.makedirs(output_dir, exist_ok=True)
    output_path = os.path.join(output_dir, filename)
    image.save(output_path)
    print(f"Saved annotated image to {output_path}")


def object_detection(client, image_name="gemini-image2.jpg", image_dir=None, output_dir="output"):
    """
    Perform object detection on an image using Google Gemini.
    
    Args:
        client (genai.Client): Initialized Gemini client
        image_name (str): Name of the input image
        image_dir (str, optional): Directory containing the input image
        output_dir (str, optional): Directory to save the output image
    """
    prompt = "Detect the 2d bounding boxes of objects in image."
    output_prompt = "Return just box_2d and labels, no additional text."
    
    image, w, h = read_image(image_name, image_dir)
    results = inference(client, image, prompt + output_prompt)
    
    try:
        cln_results = json.loads(clean_results(results))
        
        annotator = Annotator(image)
        
        for idx, item in enumerate(cln_results):
            # By default, Gemini model returns output with y coordinates first
            # Scale normalized box coordinates (0-1000) to image dimensions
            y1, x1, y2, x2 = item["box_2d"]
            y1 = y1 / 1000 * h
            x1 = x1 / 1000 * w
            y2 = y2 / 1000 * h
            x2 = x2 / 1000 * w
            
            if x1 > x2:
                x1, x2 = x2, x1  # Swap x-coordinates if needed
            if y1 > y2:
                y1, y2 = y2, y1  # Swap y-coordinates if needed
                
            annotator.box_label([x1, y1, x2, y2], label=item["label"], color=colors(idx, True))
        
        result_image = Image.fromarray(annotator.result())
        save_annotated_image(result_image, f"detection_{os.path.basename(image_name)}", output_dir)
        
        return result_image
    except json.JSONDecodeError as e:
        print(f"Error parsing results: {e}")
        print(f"Raw results: {results}")
        return None


def reasoning_based_detection(client, image_name="gemini-image2.jpg", image_dir=None, output_dir="output"):
    """
    Perform reasoning-based detection on an image using Google Gemini.
    
    Args:
        client (genai.Client): Initialized Gemini client
        image_name (str): Name of the input image
        image_dir (str, optional): Directory containing the input image
        output_dir (str, optional): Directory to save the output image
    """
    prompt = """
    Detect the 2d bounding box around:
    highlight the area of morning light +
    notebook on PC table
    potted plant near mirror.
    """
    output_prompt = "Return just box_2d and labels, no additional text."
    
    image, w, h = read_image(image_name, image_dir)
    results = inference(client, image, prompt + output_prompt)
    
    try:
        cln_results = json.loads(clean_results(results))
        
        annotator = Annotator(image)
        
        for idx, item in enumerate(cln_results):
            y1, x1, y2, x2 = item["box_2d"]
            y1 = y1 / 1000 * h
            x1 = x1 / 1000 * w
            y2 = y2 / 1000 * h
            x2 = x2 / 1000 * w
            
            if x1 > x2:
                x1, x2 = x2, x1
            if y1 > y2:
                y1, y2 = y2, y1
                
            annotator.box_label([x1, y1, x2, y2], label=item["label"], color=colors(idx, True))
        
        result_image = Image.fromarray(annotator.result())
        save_annotated_image(result_image, f"reasoning_{os.path.basename(image_name)}", output_dir)
        
        return result_image
    except json.JSONDecodeError as e:
        print(f"Error parsing results: {e}")
        print(f"Raw results: {results}")
        return None


def image_captioning(client, image_name="gemini-image4.jpg", image_dir=None):
    """
    Generate a caption for an image using Google Gemini.
    
    Args:
        client (genai.Client): Initialized Gemini client
        image_name (str): Name of the input image
        image_dir (str, optional): Directory containing the input image
    
    Returns:
        str: Generated caption
    """
    prompt = """
    What's inside the image, generate a detailed captioning in the form of short
    story, Make 4-5 lines and start each sentence on a new line.
    """
    
    image, _, _ = read_image(image_name, image_dir)
    caption = inference(client, image, prompt)
    
    print(f"\nCaption for {image_name}:\n{caption}\n")
    
    return caption


def ocr(client, image_name="gemini-image3.png", image_dir=None, output_dir="output"):
    """
    Perform OCR on an image using Google Gemini.
    
    Args:
        client (genai.Client): Initialized Gemini client
        image_name (str): Name of the input image
        image_dir (str, optional): Directory containing the input image
        output_dir (str, optional): Directory to save the output image
    """
    prompt = "Extract the text from the image"
    output_prompt = "Return just box_2d which will be location of detected text areas + label"
    
    image, w, h = read_image(image_name, image_dir)
    results = inference(client, image, prompt + output_prompt)
    
    try:
        cln_results = json.loads(clean_results(results))
        
        annotator = Annotator(image)
        
        for idx, item in enumerate(cln_results):
            y1, x1, y2, x2 = item["box_2d"]
            y1 = y1 / 1000 * h
            x1 = x1 / 1000 * w
            y2 = y2 / 1000 * h
            x2 = x2 / 1000 * w
            
            if x1 > x2:
                x1, x2 = x2, x1
            if y1 > y2:
                y1, y2 = y2, y1
                
            annotator.box_label([x1, y1, x2, y2], label=item["label"], color=colors(idx, True))
        
        result_image = Image.fromarray(annotator.result())
        save_annotated_image(result_image, f"ocr_{os.path.basename(image_name)}", output_dir)
        
        return result_image
    except json.JSONDecodeError as e:
        print(f"Error parsing results: {e}")
        print(f"Raw results: {results}")
        return None


def main():
    parser = argparse.ArgumentParser(description="Google Gemini Vision API Demo")
    parser.add_argument("--api-key", type=str, help="Google Gemini API key (alternatively, set GOOGLE_API_KEY environment variable)")
    parser.add_argument("--mode", type=str, default="all", choices=["detection", "reasoning", "caption", "ocr", "all"], 
                        help="Mode to run (default: all)")
    parser.add_argument("--image-dir", type=str, default="images", help="Directory for input images (default: images)")
    parser.add_argument("--output-dir", type=str, default="output", help="Directory for output images (default: output)")
    parser.add_argument("--image", type=str, help="Specific image to process (default: example images)")
    
    args = parser.parse_args()
    
    # Create directories if they don't exist
    os.makedirs(args.image_dir, exist_ok=True)
    os.makedirs(args.output_dir, exist_ok=True)
    
    # Setup client
    try:
        client = setup_gemini_client(args.api_key)
    except ValueError as e:
        print(f"Error: {e}")
        print("Please provide an API key using --api-key or set the GOOGLE_API_KEY environment variable.")
        return
    
    # Run the requested mode(s)
    if args.mode in ["detection", "all"]:
        print("\n=== Running Object Detection ===")
        object_detection(client, args.image or "gemini-image2.jpg", args.image_dir, args.output_dir)
    
    if args.mode in ["reasoning", "all"]:
        print("\n=== Running Reasoning-based Detection ===")
        reasoning_based_detection(client, args.image or "gemini-image2.jpg", args.image_dir, args.output_dir)
    
    if args.mode in ["caption", "all"]:
        print("\n=== Running Image Captioning ===")
        image_captioning(client, args.image or "gemini-image4.jpg", args.image_dir)
    
    if args.mode in ["ocr", "all"]:
        print("\n=== Running OCR ===")
        ocr(client, args.image or "gemini-image3.png", args.image_dir, args.output_dir)


if __name__ == "__main__":
    main()